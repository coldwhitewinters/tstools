{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e56b81dc-5126-4037-b2ec-e55168a329a3",
   "metadata": {},
   "source": [
    "# Notes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd043b89-738f-46f3-a17f-a0c10979ae02",
   "metadata": {},
   "source": [
    "- [x] Add progress bar\n",
    "- [x] Add auto arima\n",
    "- [ ] Add auto skar\n",
    "- [ ] Add baselines\n",
    "- [ ] Add metrics\n",
    "- [x] Add confidence intervals\n",
    "- [ ] Add residuals\n",
    "- [ ] Add simple validation metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9da94338-f409-4d17-b5cf-d7f2fde98380",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7803f99a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass, field\n",
    "from typing import List, Optional, Union, Any\n",
    "from typing_extensions import Protocol\n",
    "from copy import deepcopy\n",
    "from tqdm import tqdm\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "from ipywidgets import interact, widgets\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.tsa.api as tsa\n",
    "import pmdarima as pm\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (12, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "226fe35c-314f-49f2-9094-d37f976da5e2",
   "metadata": {},
   "source": [
    "# Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "586c4f4c-7494-482f-931a-f6985c54d4d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScikitModel(Protocol):\n",
    "    def fit(self, X, y, sample_weight=None): ...\n",
    "    def predict(self, X): ...\n",
    "    def score(self, X, y, sample_weight=None): ...\n",
    "    def set_params(self, **params): ...\n",
    "    def get_params(self, deep=True): ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b64f7f8-9505-4eae-830b-0f0ad02dcde5",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e29dd22d-4e46-41f5-ab77-fa95981d5a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "stocks = pd.read_csv(\"../data/all_stocks_5yr.csv\", parse_dates=[\"date\"])\n",
    "stocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdf67a75-77d4-45eb-b396-e43144f2b268",
   "metadata": {},
   "outputs": [],
   "source": [
    "stocks.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13e7e268-d402-4380-948a-30b5552d9a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "stocks = stocks.set_index(\"date\").groupby(\"Name\").resample(\"W\").mean().reset_index()\n",
    "stocks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "686d94ce-79a9-4c29-b0b4-3d82a177b549",
   "metadata": {},
   "source": [
    "# Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "907b6a38-e3a3-4464-8dee-29e226271dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def error(y, y_fcst):\n",
    "    err = y - y_fcst\n",
    "    return err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "846c947c-51f6-40c4-b6a1-39d46b35c162",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mae(y, y_fcst):\n",
    "    mae_value = error(y, y_fcst).abs().mean()\n",
    "    return mae_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d165185-5da2-4409-816b-aa0bafbc9e7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse(y, y_fcst):\n",
    "    sqe = error(y, y_fcst)**2\n",
    "    mse_value = sqe.mean()\n",
    "    return mse_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "422f2786-40ca-49a6-9d9c-b588dfd9da3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wape(y, y_fcst):\n",
    "    err = error(y, y_fcst)\n",
    "    wape_value = 100 * err.abs().sum() / y.abs().sum() \n",
    "    return wape_value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16ee7ced-c6d6-461a-a447-072dc2ad1f27",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e724bbff-0f4b-4363-8884-f18349913672",
   "metadata": {},
   "source": [
    "## Base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d84bb76-fa1f-44bd-af9d-016d658c713f",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class BaseForecaster:\n",
    "    key_col: str\n",
    "    time_col: str\n",
    "    target_cols: List[str]\n",
    "    predictor_cols: Optional[List[str]]\n",
    "    freq: str\n",
    "    fh: Optional[int] = None\n",
    "    \n",
    "    def get_keys(self, data):\n",
    "        return list(data[self.key_col].unique())\n",
    "    \n",
    "    def get_group(self, data, key):\n",
    "        subdata = data[data[self.key_col] == key].copy()\n",
    "        return subdata\n",
    "        \n",
    "    def get_indexed_series(self, data, key, col):\n",
    "        subdata = self.get_group(data, key)\n",
    "        y = subdata.set_index(self.time_col).asfreq(self.freq)[col].copy()\n",
    "        return y\n",
    "    \n",
    "    def get_data_slices(self, data, fh=1, start=0.5, stride=1):\n",
    "        train_list = []\n",
    "        data_by_key = data.groupby(self.key_col, group_keys=False)\n",
    "        n_obs = int(len(data) / len(data_by_key))\n",
    "        start_cutoff = int(start * n_obs)\n",
    "        end_cutoff = n_obs - fh\n",
    "        cutoffs = range(start_cutoff, end_cutoff+1, stride)\n",
    "        for cutoff in cutoffs:\n",
    "            data_slice = data_by_key.apply(lambda df: df.iloc[:cutoff, :])\n",
    "            train_list.append(data_slice)\n",
    "        return train_list\n",
    "    \n",
    "    def get_predictor_slices(self, predictors, fh=1, start=0.5, stride=1):\n",
    "        predictors = predictors.groupby(self.key_col, group_keys=False).apply(lambda df: df.shift(-fh))\n",
    "        predictor_slices = []\n",
    "        for pred_slice in self.get_data_slices(predictors, fh, start, stride):\n",
    "            predictor_slices.append(pred_slice.groupby(self.key_col).apply(lambda df: df.tail(fh)))\n",
    "        return predictor_slices\n",
    "    \n",
    "    def build_fcst_index(self, data, fh=1):\n",
    "        if self.fh is not None:\n",
    "            fh = self.fh\n",
    "        data_end = data[self.time_col].iloc[-1]\n",
    "        fcst_start = data_end + pd.Timedelta(1, self.freq)\n",
    "        fcst_index = pd.date_range(start=fcst_start, periods=fh, freq=self.freq)\n",
    "        fcst_index.name = self.time_col\n",
    "        return fcst_index\n",
    "    \n",
    "    def af_table(self, y, y_fcst, how=\"inner\"):\n",
    "        af_df = pd.merge(y, y_fcst, left_index=True, right_index=True, how=how)\n",
    "        af_df.columns = [\"y\", \"y_fcst\"]\n",
    "        af_df[\"error\"] = af_df[\"y\"] - af_df[\"y_fcst\"]\n",
    "        return af_df\n",
    "    \n",
    "    def af_trim(self, y, y_fcst, how=\"inner\"):\n",
    "        af_df = self.af_table(y, y_fcst, how=how)\n",
    "        return af_df[\"y\"], af_df[\"y_fcst\"]\n",
    "    \n",
    "    def historical_forecasts(self, data, predictors=None, fh=1, start=0.5, stride=1, progress=True):\n",
    "        if self.fh is not None:\n",
    "            fh = self.fh\n",
    "        hfcst = []\n",
    "        train_slices = self.get_data_slices(data, fh, start, stride)\n",
    "        if self.predictor_cols is None or predictors is None:\n",
    "            predictor_slices = len(train_slices) * [None]\n",
    "        else:\n",
    "            predictor_slices = self.get_predictor_slices(predictors, fh, start, stride)\n",
    "        slices = zip(train_slices, predictor_slices)\n",
    "        if progress:\n",
    "            slices = tqdm(list(slices))\n",
    "        for train, predictor in slices:\n",
    "            self.fit(train, progress=False)\n",
    "            fcst = self.predict(fh, predictor, progress=False)\n",
    "            hfcst.append(fcst)\n",
    "        return hfcst\n",
    "    \n",
    "    def error_table(self, data, predictors=None, fh=1, start=0.5, stride=1, progress=True):\n",
    "        hfcst = self.historical_forecasts(data, predictors, fh=fh, start=start, stride=stride, progress=progress)\n",
    "        metrics_dict = dict()\n",
    "        for key in self.get_keys(data):\n",
    "            target_metrics = dict()\n",
    "            for target in self.target_cols:\n",
    "                metrics_list = list()\n",
    "                for i, fcst in enumerate(hfcst):\n",
    "                    y = self.get_indexed_series(data, key, target)\n",
    "                    y_fcst = self.get_indexed_series(fcst, key, target + \"_fcst\")\n",
    "                    y, y_fcst = self.af_trim(y, y_fcst)\n",
    "                    err = error(y, y_fcst)\n",
    "                    metrics_list.append(err.reset_index(drop=True))\n",
    "                metrics_df = pd.concat(metrics_list, axis=1)\n",
    "                metrics_df.columns = np.arange(len(metrics_df.columns))\n",
    "                target_metrics[target] = metrics_df.T\n",
    "            metrics_dict[key] = pd.concat(target_metrics, axis=1)\n",
    "        scores_df = pd.concat(metrics_dict, axis=1)\n",
    "        return scores_df\n",
    "        \n",
    "    def backtest(self, data, predictors=None, metrics=None, agg=None, fh=1, start=0.5, stride=1, progress=True):\n",
    "        if metrics is None:\n",
    "            metrics = [mae]\n",
    "        hfcst = self.historical_forecasts(data, predictors, fh=fh, start=start, stride=stride, progress=progress)\n",
    "        metrics_dict = dict()\n",
    "        for key in self.get_keys(data):\n",
    "            target_metrics = dict()\n",
    "            for target in self.target_cols:\n",
    "                metrics_list = list()\n",
    "                for i, fcst in enumerate(hfcst):\n",
    "                    step_metrics = dict()\n",
    "                    y = self.get_indexed_series(data, key, target)\n",
    "                    y_fcst = self.get_indexed_series(fcst, key, target + \"_fcst\")\n",
    "                    y, y_fcst = self.af_trim(y, y_fcst)\n",
    "                    for metric in metrics:\n",
    "                        step_metrics[metric.__name__] = metric(y, y_fcst)\n",
    "                    metrics_list.append(pd.Series(step_metrics))\n",
    "                metrics_df = pd.DataFrame(metrics_list)\n",
    "                target_metrics[target] = metrics_df\n",
    "            metrics_dict[key] = pd.concat(target_metrics, axis=1)\n",
    "        scores_df = pd.concat(metrics_dict, axis=1)\n",
    "        if agg is not None:\n",
    "            return agg(scores_df)\n",
    "        return scores_df\n",
    "    \n",
    "    def plot_fcst(self, data, fcst, key, target, style=\"-\"):\n",
    "        target_fcst = target + \"_fcst\"\n",
    "        target_lower = target + \"_lower\"\n",
    "        target_upper = target + \"_upper\"\n",
    "        f, ax = plt.subplots()\n",
    "        y = self.get_indexed_series(data, key, target)\n",
    "        y_fcst = self.get_indexed_series(fcst, key, target_fcst)\n",
    "        y.plot(ax=ax, style=style)\n",
    "        y_fcst.plot(ax=ax, style=style)\n",
    "        if target_lower in fcst.columns and target_upper in fcst.columns:\n",
    "            y_lower = self.get_indexed_series(fcst, key, target_lower)\n",
    "            y_upper = self.get_indexed_series(fcst, key, target_upper)\n",
    "            ax.fill_between(x=y_fcst.index, y1=y_lower, y2=y_upper, alpha=0.8, color=\"lightblue\")\n",
    "        plt.legend()\n",
    "        \n",
    "    def plot_forecasts(self, data, fcst):\n",
    "        interact(\n",
    "            self.plot_fcst, \n",
    "            data=widgets.fixed(data),\n",
    "            fcst=widgets.fixed(fcst),\n",
    "            key=self.get_keys(data), \n",
    "            target=self.target_cols, \n",
    "            style=[\"-\", \".\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62c68f39-2201-445f-a796-dc4aa2749268",
   "metadata": {},
   "source": [
    "## ARIMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a73ffa15-56e0-4a9e-9151-2939976cf405",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class ARIMA(BaseForecaster):\n",
    "    arima_params: dict = field(default_factory=dict)\n",
    "    fit_params: dict = field(default_factory=dict)\n",
    "    \n",
    "    def fit(self, data):\n",
    "        self.data = data.copy()\n",
    "        self.model_dict = dict()\n",
    "        for key in self.get_keys(data):\n",
    "            model_subdict = dict()\n",
    "            for target in self.target_cols:\n",
    "                y = self.get_indexed_series(data, key, target)\n",
    "                if self.predictor_cols is None:\n",
    "                    X = None\n",
    "                else:\n",
    "                    X = self.get_indexed_series(data, key, self.predictor_cols)\n",
    "                model = tsa.arima.ARIMA(y, X, **self.arima_params).fit(**self.fit_params)\n",
    "                model_subdict[target] = model\n",
    "            self.model_dict[key] = model_subdict\n",
    "        return self\n",
    "        \n",
    "    def predict(self, fh=1, predictors=None):\n",
    "        fcst_dict = dict()\n",
    "        for key, model_subdict in self.model_dict.items():\n",
    "            fcst_subdict = dict()\n",
    "            for target, model in model_subdict.items():\n",
    "                if self.predictor_cols is None:\n",
    "                    X = None\n",
    "                else:\n",
    "                    X = self.get_indexed_series(predictors, key, self.predictor_cols)\n",
    "                y_fcst = model.forecast(fh, exog=X)\n",
    "                y_fcst.index.name = self.time_col\n",
    "                y_fcst.name = target + \"_fcst\"\n",
    "                y_fcst = y_fcst.reset_index()\n",
    "                fcst_subdict[target] = y_fcst\n",
    "            fcst_subdf = pd.concat({key: fcst.set_index(\"date\") for key, fcst in fcst_subdict.items()}, axis=1)\n",
    "            fcst_subdf.columns = fcst_subdf.columns.droplevel()\n",
    "            fcst_subdf = fcst_subdf.reset_index()\n",
    "            fcst_subdf.insert(0, self.key_col, key)\n",
    "            fcst_dict[key] = fcst_subdf\n",
    "        fcst = pd.concat(fcst_dict.values())\n",
    "        return fcst          "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acb76cd7-1738-42d9-9318-512c1fce9800",
   "metadata": {},
   "source": [
    "## AutoARIMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90530791-9c2d-45c6-8bf7-3e602ec7f49d",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class AutoARIMA(BaseForecaster):\n",
    "    arima_params: dict = field(default_factory=dict)\n",
    "    fit_params: dict = field(default_factory=dict)\n",
    "        \n",
    "    def fit_for_each_key(self, data, progress):\n",
    "        model_dict = dict()\n",
    "        data_keys = self.get_keys(data)\n",
    "        if progress:\n",
    "            data_keys = tqdm(data_keys)\n",
    "        for key in data_keys:\n",
    "            model_dict[key] = self.fit_for_each_target(data, key)\n",
    "        return model_dict\n",
    "            \n",
    "    def fit_for_each_target(self, data, key):\n",
    "        model_dict = dict()\n",
    "        for target in self.target_cols:\n",
    "            y = self.get_indexed_series(data, key, target)\n",
    "            if self.predictor_cols is None:\n",
    "                X = None\n",
    "            else:\n",
    "                X = self.get_indexed_series(data, key, self.predictor_cols)\n",
    "            model = pm.AutoARIMA(**self.arima_params)\n",
    "            model.fit(y, X, **self.fit_params)\n",
    "            model_dict[target] = model\n",
    "        return model_dict\n",
    "            \n",
    "    def predict_for_each_key(self, fh, predictors, conf_int, progress):\n",
    "        fcst_dict = dict()\n",
    "        model_items = self.model_dict.items()\n",
    "        if progress:\n",
    "            model_items = tqdm(model_items)\n",
    "        for key, models_for_key in model_items:\n",
    "            fcst_dict[key] = self.predict_for_each_target(key, models_for_key, fh, predictors, conf_int)\n",
    "        fcst = pd.concat(fcst_dict.values())\n",
    "        return fcst\n",
    "        \n",
    "    def predict_for_each_target(self, key, models_for_key, fh, predictors, conf_int):\n",
    "        fcst_dict = dict()\n",
    "        for target, model in models_for_key.items():\n",
    "            y_fcst_idx = self.build_fcst_index(self.data, fh)\n",
    "            if self.predictor_cols is None:\n",
    "                X = None\n",
    "            else:\n",
    "                X = self.get_indexed_series(predictors, key, self.predictor_cols)\n",
    "            if conf_int is None:\n",
    "                y_fcst = model.predict(n_periods=fh, X=X)\n",
    "                y_fcst = pd.DataFrame(y_fcst, index=y_fcst_idx, columns=[target + \"_fcst\"])\n",
    "            else:\n",
    "                y_fcst, y_conf = model.predict(n_periods=fh, X=X, return_conf_int=True, alpha=1-conf_int)\n",
    "                y_fcst = pd.DataFrame(y_fcst, index=y_fcst_idx, columns=[target + \"_fcst\"])\n",
    "                y_fcst[target + \"_lower\"] = y_conf[:, 0]\n",
    "                y_fcst[target + \"_upper\"] = y_conf[:, 1]\n",
    "            y_fcst = y_fcst.reset_index()\n",
    "            fcst_dict[target] = y_fcst\n",
    "        fcst_df = pd.concat({target: fcst.set_index(self.time_col) for target, fcst in fcst_dict.items()}, axis=1)\n",
    "        fcst_df.columns = fcst_df.columns.droplevel()\n",
    "        fcst_df = fcst_df.reset_index()\n",
    "        fcst_df.insert(0, self.key_col, key)\n",
    "        return fcst_df\n",
    "    \n",
    "    def fit(self, data, progress=True):\n",
    "        self.data = data.copy()\n",
    "        self.model_dict = self.fit_for_each_key(data, progress)\n",
    "        return self\n",
    "        \n",
    "    def predict(self, fh=1, predictors=None, conf_int=None, progress=True):\n",
    "        fcst = self.predict_for_each_key(fh, predictors, conf_int, progress)\n",
    "        return fcst    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "842f2ee0-dc0f-4fcf-9172-b35c7ddd7721",
   "metadata": {},
   "source": [
    "## SKAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1812f4ae-45a6-46e3-a46d-1e0e707e3bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class SKAR(BaseForecaster):\n",
    "    model: ScikitModel = None\n",
    "    scale_regressors: bool = True\n",
    "    n_lags: int = 0\n",
    "        \n",
    "    def build_lags(self, y):    \n",
    "        lags = pd.concat([y.shift(i) for i in range(self.n_lags + 1)], axis=1).dropna()\n",
    "        return lags\n",
    "    \n",
    "    def build_target(self, y):\n",
    "        target = pd.concat([y.shift(-i) for i in range(1, self.fh + 1)], axis=1).dropna()\n",
    "        return target\n",
    "    \n",
    "    def build_fcst_index(self):\n",
    "        data_end = self.data[self.time_col].iloc[-1]\n",
    "        fcst_start = data_end + pd.Timedelta(1, self.freq)\n",
    "        fcst_index = pd.date_range(start=fcst_start, periods=self.fh, freq=self.freq)\n",
    "        return fcst_index\n",
    "    \n",
    "    def fit(self, data):\n",
    "        if self.model is None:\n",
    "            self.model = LinearRegression()\n",
    "        self.data = data.copy()\n",
    "        self.model_dict = dict()\n",
    "        self.scaler_dict = dict()\n",
    "        for key in self.get_keys(data):\n",
    "            model_subdict = dict()\n",
    "            scaler_subdict = dict()\n",
    "            for target in self.target_cols:\n",
    "                target_data = self.get_indexed_series(data, key, target)\n",
    "                if self.predictor_cols is not None:\n",
    "                    predictor_data = self.get_indexed_series(data, key, self.predictor_cols)\n",
    "                else:\n",
    "                    predictor_data = None\n",
    "                y_target = self.build_target(target_data)\n",
    "                y_lags = self.build_lags(target_data)\n",
    "                YX = pd.concat([y_target, y_lags, predictor_data], axis=1, join=\"inner\").to_numpy()\n",
    "                Y = YX[:, :self.fh]\n",
    "                X = YX[:, self.fh:]\n",
    "                if self.scale_regressors:\n",
    "                    scaler = StandardScaler()\n",
    "                    X = scaler.fit_transform(X)\n",
    "                    scaler_subdict[target] = scaler\n",
    "                model = deepcopy(self.model)\n",
    "                model.fit(X, Y)\n",
    "                model_subdict[target] = model\n",
    "            self.model_dict[key] = model_subdict\n",
    "            self.scaler_dict[key] = scaler_subdict\n",
    "        return self\n",
    "    \n",
    "    def predict(self, fh=None, predictors=None):\n",
    "        fcst_dict = dict()\n",
    "        for key, model_subdict in self.model_dict.items():\n",
    "            fcst_subdict = dict()\n",
    "            for target, model in model_subdict.items():\n",
    "                target_data = self.get_indexed_series(self.data, key, [target])\n",
    "                y_lags = np.flip(target_data.tail(self.n_lags+1).to_numpy())\n",
    "                if self.predictor_cols is not None:\n",
    "                    predictor_data = self.get_indexed_series(self.data, key, self.predictor_cols)\n",
    "                    last_predictors = predictor_data.tail(1).to_numpy()\n",
    "                    X = np.concatenate([y_lags, last_predictors]).T\n",
    "                else:\n",
    "                    X = y_lags.T\n",
    "                if self.scale_regressors:\n",
    "                    scaler = self.scaler_dict[key][target]\n",
    "                    X = scaler.transform(X)\n",
    "                y_fcst = model.predict(X)\n",
    "                y_fcst_index = self.build_fcst_index()\n",
    "                y_fcst = pd.Series(y_fcst.flatten(), index=y_fcst_index)\n",
    "                y_fcst.index.name = self.time_col\n",
    "                y_fcst.name = target + \"_fcst\"\n",
    "                y_fcst = y_fcst.reset_index()\n",
    "                fcst_subdict[target] = y_fcst\n",
    "            fcst_subdf = pd.concat({key: fcst.set_index(\"date\") for key, fcst in fcst_subdict.items()}, axis=1)\n",
    "            fcst_subdf.columns = fcst_subdf.columns.droplevel()\n",
    "            fcst_subdf = fcst_subdf.reset_index()\n",
    "            fcst_subdf.insert(0, self.key_col, key)\n",
    "            fcst_dict[key] = fcst_subdf\n",
    "        fcst = pd.concat(fcst_dict.values())\n",
    "        return fcst\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21c882ae-5073-49e4-8d28-814559e6f9dd",
   "metadata": {},
   "source": [
    "# Sandbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b06f818e-3f98-4451-a53d-82f406db95a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import darts.models\n",
    "import darts.metrics\n",
    "from darts.timeseries import TimeSeries\n",
    "from warnings import filterwarnings\n",
    "filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb4da8e4-407a-47a4-b811-0a927ca84d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data = stocks[stocks.Name.isin([\"A\", \"AAL\"])]\n",
    "data = stocks[stocks.Name.isin([\"A\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e94725b8-b9f4-4281-8de7-da07bdff163d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoARIMA(key_col=\"Name\", time_col=\"date\", target_cols=[\"open\"], predictor_cols=[\"close\"], freq=\"W\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "297952b2-0315-4b44-a629-9b5d1dfb227c",
   "metadata": {},
   "outputs": [],
   "source": [
    "hfcst = model.historical_forecasts(data, predictors=data, fh=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6dbc8e9-4050-470d-8757-1e5857cd9146",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_score = model.backtest(data, predictors=data, metrics=[mae], agg=np.mean, fh=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e62fbbb0-2698-435f-82ad-09e8a8bb6db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data.set_index(\"date\")[[\"open\"]]\n",
    "X = data.set_index(\"date\")[[\"close\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e25d6d3-7068-4bb3-aad4-ca750b64e10d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = TimeSeries(y)\n",
    "X = TimeSeries(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "502c28bf-adc9-4ac7-a803-778440ab1ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "arima = pm.AutoARIMA()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46bf8cd2-d424-408b-8636-0f23385d676c",
   "metadata": {},
   "outputs": [],
   "source": [
    "arima = darts.models.AutoARIMA()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a6fd8b3-a58f-48fc-a7e1-7b68b1661043",
   "metadata": {},
   "outputs": [],
   "source": [
    "score = arima.backtest(y, X, forecast_horizon=10, verbose=True, reduction=None, metric=darts.metrics.mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2531d7f-1a97-4bd3-a865-1276a1c09122",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(score[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bab6461-4fe6-4f35-9b2e-1fe9ee880b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.plot_forecasts(data, hfcst[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32ec0d0a-92db-479e-9e80-0a261f562d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data[[\"date\", \"open\"]].set_index(\"date\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78c0e1b1-5fed-4207-944c-e06ee9c2842c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data[[\"date\", \"close\"]].set_index(\"date\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "037a6662-2641-4d38-bf8b-5d83e73edb06",
   "metadata": {},
   "outputs": [],
   "source": [
    "base = BaseForecaster(key_col=\"Name\", time_col=\"date\", target_cols=[\"open\"], predictor_cols=[\"close\"], freq=\"W\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ac94cfd-55d9-438a-a9b7-45798fd71c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = pm.AutoARIMA()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e5bd5af-c40c-46c2-a26d-1dc8615009dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a78d9aea-e1b8-4b9f-a816-126ca1d3f08f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(y[:-10], X[:-10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd0fcb81-8e01-41a2-b9c0-292df136dc8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fcst, conf_int = model.predict(X=X[-10:], return_conf_int=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffc0c0e9-ff98-4af0-b4dc-0d4470692ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "fcst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d49a0d3d-8a57-46ae-a825-3991a2e47023",
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f64b450-63c2-4ea6-a2d3-ab8bc13c61e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fcst_ix = base.build_fcst_index(data[:-10], fh=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12db6743-f0f2-4089-aaf5-3988f3b836f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "fcst_df = pd.DataFrame(fcst, columns=base.target_cols, index=fcst_ix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7ac9e8a-aa82-4436-8f78-c776d97a4937",
   "metadata": {},
   "outputs": [],
   "source": [
    "fcst_df[base.target_cols[0] + \"_lower\"] = conf_int[:, 0]\n",
    "fcst_df[base.target_cols[0] + \"_upper\"] = conf_int[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3f30486-d879-4bf3-91fd-d8afd1844257",
   "metadata": {},
   "outputs": [],
   "source": [
    "fcst_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7acbc7d1-59c4-4eec-8ae5-741b3199cd66",
   "metadata": {},
   "outputs": [],
   "source": [
    "fcst = pd.Series(fcst, index=fcst_ix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "384905ad-ff32-4132-b577-df4ec88dba78",
   "metadata": {},
   "outputs": [],
   "source": [
    "y.plot()\n",
    "fcst.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07e568f7-6fc6-4e2e-975b-5d1c50a273e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df438a4f-0e1b-46fe-9997-882697fc75d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c0f0e52-f730-47f0-8b79-9b088f5838be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c8f1b7a-2b17-42e7-a03e-09a57922415d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01400126-bf72-4028-b4c9-9f0d37a6c812",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afe0177f-950e-4252-a185-2e55931f15ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e3ee07c-b42c-4241-b25f-575fedac4d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "series = TimeSeries(data.set_index(\"date\")[[\"open\"]])\n",
    "exog = TimeSeries(data.set_index(\"date\")[[\"close_lag\"]])\n",
    "arima_darts = darts.models.ARIMA(p=12)\n",
    "arima_darts.fit(series[:-10], exog[:-10])\n",
    "fcst_darts = arima_darts.predict(n=10, exog=exog[-10:])\n",
    "scores_darts = arima_darts.backtest(series, exog, forecast_horizon=10, metric=darts.metrics.mae, reduction=None, verbose=True)[1:]\n",
    "hfcst_darts = arima_darts.historical_forecasts(series, exog, forecast_horizon=10, last_points_only=False, verbose=True)[1:]\n",
    "\n",
    "print(np.mean(scores_darts))\n",
    "series.plot()\n",
    "fcst_darts.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54ebc466-b476-4c7d-8a11-a8e6b7055218",
   "metadata": {},
   "outputs": [],
   "source": [
    "arima = ARIMA(key_col=\"Name\", time_col=\"date\", target_cols=[\"open\"], predictor_cols=[\"close_lag\"], freq=\"W\", fh=10, arima_params={\"order\": (12, 1, 0)})\n",
    "arima.fit(data[:-10])\n",
    "fcst = arima.predict(fh=10, predictors=data[-10:])\n",
    "scores = arima.backtest(data, predictors=data, metrics=[mae], fh=10)\n",
    "hfcst = arima.historical_forecasts(data, predictors=data, fh=10)\n",
    "\n",
    "print(scores.mean())\n",
    "arima.plot_forecasts(data, fcst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "550cc7a3-25f2-46a3-8dea-a3585e3c4186",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43c8e6bc-f13e-4d82-8ea0-07eedaeb3925",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MultiOutputRegressor(SVR(kernel=\"linear\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d0c8c33-90d7-4c0b-8ac3-4048babdee3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MultiOutputRegressor(GradientBoostingRegressor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97c9493e-7f4e-4901-b180-c950d1bcf62b",
   "metadata": {},
   "outputs": [],
   "source": [
    "skar = SKAR(key_col=\"Name\", time_col=\"date\", target_cols=[\"open\"], predictor_cols=None, freq=\"W\", fh=10, n_lags=12, model=model, scale_regressors=True)\n",
    "skar.fit(data[:-10])\n",
    "fcst = skar.predict()\n",
    "scores = skar.backtest(data, metrics=[mae])\n",
    "hfcst = skar.historical_forecasts(data)\n",
    "\n",
    "print(scores.mean())\n",
    "skar.plot_forecasts(data, fcst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a753d77-82c8-4ef4-8c46-822754203bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_darts = darts.models.LinearRegressionModel(lags=12, lags_exog=12)\n",
    "linear_darts.fit(series[:-10], exog[:-10])\n",
    "fcst_darts = linear_darts.predict(n=10, exog=exog[-10:])\n",
    "\n",
    "series.plot()\n",
    "fcst_darts.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a88ee68e-8895-42be-9444-3e5ff541285b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "125ef654-6932-4be1-9e47-78e75c956c57",
   "metadata": {},
   "source": [
    "# Scrapyard"
   ]
  },
  {
   "cell_type": "raw",
   "id": "1f8700b4-3887-4a65-b295-c622286ab8ce",
   "metadata": {},
   "source": [
    "@dataclass\n",
    "class TestModel(BaseForecaster):\n",
    "    trend: str = None\n",
    "    damped: bool = False\n",
    "    seasonal: str = None\n",
    "    seasonal_periods: int = None\n",
    "        \n",
    "    def fit(self, data):\n",
    "        self.data = data.copy() \n",
    "        self.model_dict = dict()\n",
    "        for key in data[self.key_col].unique():\n",
    "            subdata = data[data[self.key_col] == key]\n",
    "            model_subdict = dict()\n",
    "            for target in self.target_cols:\n",
    "                model = TestSingleModel(\n",
    "                    time=self.time_col,\n",
    "                    target=target,\n",
    "                    freq=self.freq,\n",
    "                    trend=self.trend, \n",
    "                    damped=self.damped, \n",
    "                    seasonal=self.seasonal, \n",
    "                    seasonal_periods=self.seasonal_periods\n",
    "                )\n",
    "                model.fit(subdata)\n",
    "                model_subdict[target] = model\n",
    "            self.model_dict[key] = model_subdict\n",
    "        \n",
    "    def predict(self, fh=1):\n",
    "        fcst_dict = dict()\n",
    "        for key, model_subdict in self.model_dict.items():\n",
    "            fcst_subdict = dict()\n",
    "            for target, model in model_subdict.items():\n",
    "                fcst = model.predict(fh)\n",
    "                fcst_subdict[target] = fcst\n",
    "            fcst_subdf = pd.concat({key: fcst.set_index(\"date\") for key, fcst in fcst_subdict.items()}, axis=1)\n",
    "            fcst_subdf.columns = fcst_subdf.columns.droplevel()\n",
    "            fcst_subdf = fcst_subdf.reset_index()\n",
    "            fcst_subdf.insert(0, self.key_col, key)\n",
    "            fcst_dict[key] = fcst_subdf\n",
    "        fcst = pd.concat(fcst_dict.values())\n",
    "        return fcst"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
